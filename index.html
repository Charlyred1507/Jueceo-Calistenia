<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Detector de Movimiento Calistenia</title>
  <style>
    body {
      margin: 0;
      background: #111;
      color: #fff;
      font-family: 'Poppins', sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 100vh;
      overflow: hidden;
    }
    video, canvas {
      position: absolute;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      width: 100%;
      height: auto;
      max-height: 100vh;
      border-radius: 12px;
      object-fit: cover;
    }
    #status {
      position: absolute;
      bottom: 20px;
      background: rgba(0, 0, 0, 0.7);
      padding: 10px 20px;
      border-radius: 8px;
      font-size: 1rem;
      z-index: 10;
    }
    #startBtn {
      position: absolute;
      top: 20px;
      background: #28a745;
      border: none;
      color: white;
      padding: 12px 24px;
      border-radius: 8px;
      font-size: 1rem;
      cursor: pointer;
      z-index: 10;
    }
  </style>
</head>
<body>
  <button id="startBtn">Activar Cámara</button>
  <video id="video" playsinline autoplay muted></video>
  <canvas id="output"></canvas>
  <div id="status">Esperando cámara...</div>

  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.17.0"></script>
  <!-- Pose Detection -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('output');
    const ctx = canvas.getContext('2d');
    const statusEl = document.getElementById('status');
    const startBtn = document.getElementById('startBtn');
    let detector;

    async function initCamera() {
      statusEl.textContent = "Iniciando cámara...";
      startBtn.disabled = true;
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          video: { facingMode: "environment" }
        });
        video.srcObject = stream;
        await new Promise((res) => video.onloadedmetadata = res);
        statusEl.textContent = "Cámara activa ✅";
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        detectPose();
      } catch (err) {
        console.error("Error cámara:", err);
        statusEl.textContent = "❌ No se pudo acceder a la cámara";
        startBtn.disabled = false;
      }
    }

    async function initDetector() {
      try {
        statusEl.textContent = "Cargando detector...";
        detector = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, {
          modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING
        });
        statusEl.textContent = "Detector activo ✅";
      } catch (err) {
        console.error("Error al cargar el detector:", err);
        statusEl.textContent = "⚠️ Detector no disponible";
      }
    }

    async function detectPose() {
      if (!detector) {
        await initDetector();
      }
      const detect = async () => {
        if (video.readyState >= 2) {
          const poses = await detector.estimatePoses(video);
          ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
          if (poses.length > 0) {
            drawSkeleton(poses[0]);
          }
        }
        requestAnimationFrame(detect);
      };
      detect();
    }

    function drawSkeleton(pose) {
      const keypoints = pose.keypoints;
      ctx.fillStyle = "#00FF00";
      ctx.lineWidth = 2;
      keypoints.forEach(pt => {
        if (pt.score > 0.4) {
          ctx.beginPath();
          ctx.arc(pt.x, pt.y, 5, 0, 2 * Math.PI);
          ctx.fill();
        }
      });
    }

    startBtn.addEventListener('click', initCamera);
  </script>
</body>
</html>